# Guide Complet des Tests Unitaires
## iaPostemanage - Infrastructure de Test

---

## üìã Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Installation](#installation)
3. [Ex√©cution des tests](#ex√©cution-des-tests)
4. [Structure des tests](#structure-des-tests)
5. [Couverture de code](#couverture-de-code)
6. [√âcrire de nouveaux tests](#√©crire-de-nouveaux-tests)
7. [CI/CD Integration](#cicd-integration)

---

## üéØ Vue d'ensemble

### Tests Backend (Python/Flask)

**Framework:** pytest + pytest-cov + pytest-mock
**Couverture cible:** 80%+
**Localisation:** `core/backend/tests/`

#### Modules test√©s :

- ‚úÖ **database.py** - Initialisation DB, mod√®les
- ‚úÖ **db_helpers.py** - Fonctions CRUD (9 fonctions)
- ‚úÖ **audit_utils.py** - Audit trail RGPD (4 fonctions)
- ‚úÖ **app.py** - Routes API REST
- ‚úÖ **models_extended.py** - Mod√®les √©tendus
- ‚úÖ **routes/documents.py** - Upload/analyse documents
- ‚úÖ **validate_env.py** - Validation configuration

#### Types de tests :

```python
# Tests unitaires
@pytest.mark.unit
def test_create_dossier(): ...

# Tests d'int√©gration
@pytest.mark.integration  
def test_full_workflow(): ...

# Tests API
@pytest.mark.api
def test_get_dossiers_endpoint(): ...

# Tests audit
@pytest.mark.audit
def test_log_audit_creates_entry(): ...
```

### Tests Frontend (TypeScript/Next.js)

**Framework:** Jest + Testing Library
**Couverture cible:** 70%+
**Localisation:** `nextjs-app/__tests__/`

#### Composants test√©s :

- ‚ö†Ô∏è **En cours d'impl√©mentation**
- Components React
- Hooks personnalis√©s
- Utilitaires
- API calls

---

## üöÄ Installation

### Backend

```powershell
cd core/backend

# Installer d√©pendances de test
pip install pytest pytest-cov pytest-mock pytest-flask

# V√©rifier installation
pytest --version
```

### Frontend

```powershell
cd nextjs-app

# Installer d√©pendances de test
npm install --save-dev jest @testing-library/react @testing-library/jest-dom @testing-library/user-event jest-environment-jsdom

# V√©rifier installation
npm test -- --version
```

---

## üß™ Ex√©cution des tests

### Script PowerShell Unifi√© (Recommand√©)

```powershell
# Tous les tests avec coverage
.\run_tests.ps1

# Backend uniquement
.\run_tests.ps1 -Backend

# Frontend uniquement
.\run_tests.ps1 -Frontend

# Mode watch (d√©veloppement)
.\run_tests.ps1 -Watch

# Verbeux
.\run_tests.ps1 -Verbose

# Test sp√©cifique
.\run_tests.ps1 -Backend -TestPath "tests/test_db_helpers.py::test_create_dossier"
```

### Backend - Commandes manuelles

```powershell
cd core/backend

# Tous les tests
pytest tests/ -v

# Avec coverage
pytest tests/ -v --cov=. --cov-report=html --cov-report=term-missing

# Test sp√©cifique
pytest tests/test_complete.py::TestDatabaseHelpers::test_create_dossier -v

# Avec markers
pytest -m unit  # Tests unitaires uniquement
pytest -m integration  # Tests d'int√©gration
pytest -m "not slow"  # Exclure tests lents

# Mode watch (rerun automatique)
pytest-watch tests/

# Parall√©lisation (plus rapide)
pytest tests/ -n auto  # Requiert pytest-xdist
```

### Frontend - Commandes manuelles

```powershell
cd nextjs-app

# Tous les tests
npm test

# Avec coverage
npm test -- --coverage

# Mode watch
npm test -- --watch

# Test sp√©cifique
npm test -- ComponentName.test.tsx

# Update snapshots
npm test -- -u
```

---

## üìÅ Structure des tests

### Backend

```
core/backend/
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py              # Fixtures partag√©es
‚îÇ   ‚îú‚îÄ‚îÄ test_complete.py         # Tests principaux
‚îÇ   ‚îú‚îÄ‚îÄ test_db_helpers.py       # Tests CRUD
‚îÇ   ‚îú‚îÄ‚îÄ test_audit_utils.py      # Tests audit
‚îÇ   ‚îú‚îÄ‚îÄ test_documents.py        # Tests documents
‚îÇ   ‚îú‚îÄ‚îÄ test_api_routes.py       # Tests API
‚îÇ   ‚îî‚îÄ‚îÄ __pycache__/
‚îú‚îÄ‚îÄ pytest.ini                   # Configuration pytest
‚îú‚îÄ‚îÄ htmlcov/                     # Rapports coverage HTML
‚îî‚îÄ‚îÄ coverage.json                # Donn√©es coverage
```

### Fixtures disponibles (conftest.py)

```python
# Application et client
@pytest.fixture
def app(): ...           # Application Flask de test

@pytest.fixture  
def client(): ...        # Client HTTP

# Authentification
@pytest.fixture
def test_user(): ...     # Utilisateur standard

@pytest.fixture
def admin_user(): ...    # Administrateur

@pytest.fixture
def auth_headers(): ...  # Headers JWT valides

# Donn√©es de test
@pytest.fixture
def test_client_model(): ...  # Client
@pytest.fixture
def test_dossier(): ...       # Dossier
@pytest.fixture
def test_facture(): ...       # Facture
@pytest.fixture
def test_document(): ...      # Document

# Fichiers temporaires
@pytest.fixture
def mock_pdf_file(): ...      # PDF de test
@pytest.fixture
def mock_image_file(): ...    # Image de test

# Mocks externes
@pytest.fixture
def mock_ollama_response(): ...  # R√©ponse IA
@pytest.fixture
def mock_smtp_server(): ...      # Serveur email
```

---

## üìä Couverture de code

### Objectifs

| Module | Couverture cible | Statut actuel |
|--------|------------------|---------------|
| db_helpers.py | 90%+ | ‚ö†Ô∏è En cours |
| audit_utils.py | 95%+ | ‚ö†Ô∏è En cours |
| routes/documents.py | 80%+ | ‚ö†Ô∏è En cours |
| app.py | 75%+ | ‚ö†Ô∏è En cours |
| **Global** | **80%+** | ‚ö†Ô∏è En cours |

### Visualiser la couverture

```powershell
# Backend
cd core/backend
pytest tests/ --cov=. --cov-report=html
start htmlcov/index.html  # Ouvre dans navigateur

# Frontend  
cd nextjs-app
npm test -- --coverage
start coverage/lcov-report/index.html
```

### Interpr√©ter les rapports

- **Vert (>80%)** : Excellente couverture ‚úÖ
- **Jaune (60-80%)** : Couverture acceptable ‚ö†Ô∏è
- **Rouge (<60%)** : Couverture insuffisante ‚ùå

### Exclure du coverage

```ini
# pytest.ini
[coverage:run]
omit =
    tests/*
    venv/*
    */migrations/*
    conftest.py
```

---

## ‚úçÔ∏è √âcrire de nouveaux tests

### Template test unitaire (Backend)

```python
import pytest
from unittest.mock import Mock, patch

class TestMyModule:
    """Tests pour my_module.py"""
    
    def test_my_function_success(self, app, test_user):
        """Test cas nominal"""
        with app.app_context():
            # Arrange
            data = {'key': 'value'}
            
            # Act
            result = my_function(data)
            
            # Assert
            assert result is not None
            assert result.key == 'value'
    
    def test_my_function_error(self, app):
        """Test cas d'erreur"""
        with app.app_context():
            with pytest.raises(ValueError):
                my_function(None)
    
    @patch('my_module.external_service')
    def test_my_function_with_mock(self, mock_service, app):
        """Test avec mock service externe"""
        # Configure mock
        mock_service.return_value = {'status': 'ok'}
        
        # Test
        result = my_function()
        
        # V√©rifications
        assert result['status'] == 'ok'
        mock_service.assert_called_once()
```

### Template test API (Backend)

```python
class TestMyAPI:
    """Tests pour endpoint /api/my-route"""
    
    def test_get_endpoint_success(self, client, auth_headers):
        """Test GET avec authentification"""
        response = client.get('/api/my-route', headers=auth_headers)
        
        assert response.status_code == 200
        data = response.get_json()
        assert isinstance(data, list)
    
    def test_post_endpoint_validation(self, client, auth_headers):
        """Test POST avec validation"""
        invalid_data = {'missing': 'required_field'}
        
        response = client.post(
            '/api/my-route',
            json=invalid_data,
            headers=auth_headers
        )
        
        assert response.status_code == 400
        data = response.get_json()
        assert 'error' in data
    
    def test_unauthorized_access(self, client):
        """Test acc√®s sans authentification"""
        response = client.get('/api/my-route')
        assert response.status_code == 401
```

### Template test Frontend (React)

```typescript
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import '@testing-library/jest-dom';
import MyComponent from '@/components/MyComponent';

describe('MyComponent', () => {
  it('renders correctly', () => {
    render(<MyComponent title="Test" />);
    
    expect(screen.getByText('Test')).toBeInTheDocument();
  });
  
  it('handles user interaction', async () => {
    render(<MyComponent />);
    
    const button = screen.getByRole('button', { name: /submit/i });
    fireEvent.click(button);
    
    await waitFor(() => {
      expect(screen.getByText('Success')).toBeInTheDocument();
    });
  });
  
  it('calls API on submit', async () => {
    const mockFetch = jest.fn(() => 
      Promise.resolve({ ok: true, json: () => Promise.resolve({}) })
    );
    global.fetch = mockFetch;
    
    render(<MyComponent />);
    
    fireEvent.submit(screen.getByRole('form'));
    
    await waitFor(() => {
      expect(mockFetch).toHaveBeenCalledWith('/api/endpoint', expect.any(Object));
    });
  });
});
```

---

## üîÑ CI/CD Integration

### GitHub Actions

```yaml
# .github/workflows/tests.yml
name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd core/backend
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests
        run: |
          cd core/backend
          pytest tests/ --cov=. --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./core/backend/coverage.xml
  
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: |
          cd nextjs-app
          npm ci
      
      - name: Run tests
        run: |
          cd nextjs-app
          npm test -- --coverage
```

### Pre-commit Hook

```bash
# .git/hooks/pre-commit
#!/bin/sh

echo "üß™ Running tests before commit..."

# Backend tests
cd core/backend
pytest tests/ -q || exit 1

# Frontend tests
cd ../../nextjs-app
npm test -- --watchAll=false || exit 1

echo "‚úÖ All tests passed!"
exit 0
```

---

## üêõ Troubleshooting

### Probl√®me: Import errors

```powershell
# Solution: Ajouter PYTHONPATH
$env:PYTHONPATH = "c:\Users\moros\Desktop\iaPostemanage\core\backend"
pytest tests/
```

### Probl√®me: Database locked

```python
# Solution: Utiliser SQLite en m√©moire
@pytest.fixture
def app():
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///:memory:'
```

### Probl√®me: Tests lents

```powershell
# Solution: Parall√©lisation
pip install pytest-xdist
pytest tests/ -n auto
```

### Probl√®me: Coverage incompl√®te

```powershell
# Identifier fichiers non couverts
pytest --cov=. --cov-report=term-missing

# Focus sur un module
pytest tests/test_db_helpers.py --cov=db_helpers --cov-report=html
```

---

## üìà M√©triques de qualit√©

### Commandes utiles

```powershell
# Compter les tests
pytest --collect-only | Select-String "test session starts"

# Tests les plus lents
pytest --durations=10

# Tests qui √©chouent en premier
pytest -x  # Stop au premier √©chec
pytest --maxfail=3  # Stop apr√®s 3 √©checs

# Rapport JUnit (pour CI)
pytest --junitxml=test-results.xml
```

---

## üìö Ressources

### Documentation

- [Pytest](https://docs.pytest.org/)
- [Testing Library](https://testing-library.com/)
- [Jest](https://jestjs.io/)
- [Coverage.py](https://coverage.readthedocs.io/)

### Best Practices

1. **AAA Pattern** : Arrange ‚Üí Act ‚Üí Assert
2. **Test isolation** : Chaque test ind√©pendant
3. **Noms descriptifs** : `test_create_dossier_with_missing_fields`
4. **Mock services externes** : Ne pas d√©pendre d'APIs
5. **Tests rapides** : <1s par test unitaire

---

## üéì Exemples complets

### Test CRUD complet

```python
class TestDossierCRUD:
    def test_create(self, app, test_user):
        """CREATE"""
        dossier = create_dossier({...}, test_user.id)
        assert dossier.id is not None
    
    def test_read(self, app, test_dossier):
        """READ"""
        dossiers = get_all_dossiers_with_creator()
        assert len(dossiers) >= 1
    
    def test_update(self, app, test_dossier):
        """UPDATE"""
        updated = update_dossier(test_dossier.id, {'statut': 'termine'})
        assert updated.statut == 'termine'
    
    def test_delete(self, app, test_dossier):
        """DELETE"""
        result = delete_dossier(test_dossier.id)
        assert result is True
```

### Test avec mock Ollama

```python
@patch('routes.documents.requests.post')
def test_verify_document_ai(mock_post, app, mock_pdf_file):
    """Test v√©rification IA"""
    # Mock r√©ponse Ollama
    mock_post.return_value.json.return_value = {
        'response': 'Document valide: passeport fran√ßais'
    }
    
    # Test
    result = verify_document_ai(mock_pdf_file, 'passport')
    
    # V√©rifications
    assert result['verified'] is True
    assert 'passeport' in result['details'].lower()
    mock_post.assert_called_once()
```

---

**Derni√®re mise √† jour :** 22 d√©cembre 2024  
**Version :** 1.0.0  
**Auteur :** iaPostemanage Team
