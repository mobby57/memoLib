"""
AI Router - Orchestration intelligente multi-mod√®les
Route vers Ollama, GPT-4, Claude selon contexte
"""
import os
import asyncio
from typing import Dict, List, Optional, Any
from enum import Enum
import hashlib
import json


class AIModel(str, Enum):
    """Mod√®les IA disponibles"""
    OLLAMA_LLAMA3 = "ollama:llama3:8b"
    OPENAI_GPT4 = "openai:gpt-4o-mini"
    ANTHROPIC_CLAUDE = "anthropic:claude-3-haiku"


class RoutingStrategy(str, Enum):
    """Strat√©gies de routage"""
    COST_OPTIMIZED = "cost"      # Pr√©f√®re Ollama gratuit
    SPEED_OPTIMIZED = "speed"    # Pr√©f√®re le plus rapide
    QUALITY_OPTIMIZED = "quality"  # Pr√©f√®re le plus pr√©cis
    CONSENSUS = "consensus"      # Vote multi-mod√®les


class IntelligentAIRouter:
    """Router qui choisit le meilleur mod√®le selon contexte"""
    
    def __init__(self):
        # Co√ªts par 1k tokens (USD)
        self.costs = {
            AIModel.OLLAMA_LLAMA3: 0.0,      # Gratuit (local)
            AIModel.OPENAI_GPT4: 0.00015,    # $0.15/1M tokens
            AIModel.ANTHROPIC_CLAUDE: 0.00025  # $0.25/1M tokens
        }
        
        # Latences moyennes (secondes)
        self.avg_latency = {
            AIModel.OLLAMA_LLAMA3: 5.0,
            AIModel.OPENAI_GPT4: 2.0,
            AIModel.ANTHROPIC_CLAUDE: 3.0
        }
        
        # Score qualit√© (0-100)
        self.quality_score = {
            AIModel.OLLAMA_LLAMA3: 75,
            AIModel.OPENAI_GPT4: 92,
            AIModel.ANTHROPIC_CLAUDE: 88
        }
        
        # Stats utilisation
        self.usage_stats = {
            model: {'calls': 0, 'tokens': 0, 'cost': 0.0}
            for model in AIModel
        }
    
    async def route_analysis(
        self,
        document: str,
        context: Dict[str, Any],
        strategy: RoutingStrategy = RoutingStrategy.COST_OPTIMIZED
    ) -> Dict[str, Any]:
        """
        Router intelligent vers meilleur mod√®le
        
        Args:
            document: Texte √† analyser
            context: M√©tadonn√©es (priority, type, etc.)
            strategy: Strat√©gie routage
            
        Returns:
            R√©sultat analyse avec m√©tadonn√©es mod√®le
        """
        
        # Choisir mod√®le selon strat√©gie
        model = self._select_model(document, context, strategy)
        
        print(f"ü§ñ AI Router: {model} s√©lectionn√© (strat√©gie: {strategy})")
        
        # Analyser avec mod√®le choisi
        if model == AIModel.OLLAMA_LLAMA3:
            result = await self._analyze_ollama(document)
        elif model == AIModel.OPENAI_GPT4:
            result = await self._analyze_gpt4(document)
        elif model == AIModel.ANTHROPIC_CLAUDE:
            result = await self._analyze_claude(document)
        
        # Enrichir avec m√©tadonn√©es
        result['_metadata'] = {
            'model': model,
            'strategy': strategy,
            'cost_usd': self._calculate_cost(model, len(document)),
            'routing_reason': self._get_routing_reason(document, context, model)
        }
        
        # Mettre √† jour stats
        self._update_stats(model, len(document))
        
        return result
    
    def _select_model(
        self,
        document: str,
        context: Dict,
        strategy: RoutingStrategy
    ) -> AIModel:
        """S√©lection mod√®le selon r√®gles"""
        
        doc_length = len(document)
        priority = context.get('priority', 'normal')
        doc_type = context.get('type', 'unknown')
        
        # R√®gles de routage
        
        # CONSENSUS pour documents critiques
        if context.get('critical') or doc_type == 'legal':
            # Consensus sera g√©r√© par route_consensus()
            return AIModel.OPENAI_GPT4  # Fallback GPT-4
        
        # SPEED pour urgences
        if strategy == RoutingStrategy.SPEED_OPTIMIZED or priority == 'urgent':
            return AIModel.OPENAI_GPT4  # Plus rapide
        
        # QUALITY pour juridique/complexe
        if strategy == RoutingStrategy.QUALITY_OPTIMIZED or doc_type in ['legal', 'contract']:
            return AIModel.OPENAI_GPT4  # Meilleure qualit√©
        
        # COST pour le reste (d√©faut)
        if doc_length < 3000:
            return AIModel.OLLAMA_LLAMA3  # Gratuit et rapide pour courts docs
        elif doc_length < 10000:
            return AIModel.OPENAI_GPT4  # Bon compromis longs docs
        else:
            return AIModel.ANTHROPIC_CLAUDE  # Meilleur context window
    
    async def route_consensus(
        self,
        document: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Consensus multi-mod√®les pour documents critiques
        Vote majoritaire sur deadline/urgence
        """
        print("üîÆ AI Router: Mode CONSENSUS activ√© - 3 mod√®les")
        
        # Analyser avec 3 mod√®les en parall√®le
        results = await asyncio.gather(
            self._analyze_ollama(document),
            self._analyze_gpt4(document),
            self._analyze_claude(document),
            return_exceptions=True
        )
        
        # Filtrer erreurs
        valid_results = [r for r in results if not isinstance(r, Exception)]
        
        if len(valid_results) < 2:
            raise ValueError("Consensus impossible: moins de 2 mod√®les disponibles")
        
        # Merger r√©sultats par vote majoritaire
        consensus = self._merge_consensus(valid_results)
        
        consensus['_metadata'] = {
            'model': 'consensus',
            'models_used': [AIModel.OLLAMA_LLAMA3, AIModel.OPENAI_GPT4, AIModel.ANTHROPIC_CLAUDE],
            'confidence': len(valid_results) / 3.0,
            'cost_usd': sum(self._calculate_cost(m, len(document)) for m in AIModel)
        }
        
        return consensus
    
    def _merge_consensus(self, results: List[Dict]) -> Dict:
        """Vote majoritaire sur champs cl√©s"""
        consensus = {}
        
        # Vote sur urgence
        urgences = [r.get('urgence') for r in results if 'urgence' in r]
        if urgences:
            consensus['urgence'] = max(set(urgences), key=urgences.count)
        
        # Moyenne d√©lais
        delais = [r.get('delai_jours') for r in results if 'delai_jours' in r]
        if delais:
            consensus['delai_jours'] = int(sum(delais) / len(delais))
        
        # Vote type document
        types = [r.get('type_document') for r in results if 'type_document' in r]
        if types:
            consensus['type_document'] = max(set(types), key=types.count)
        
        # Merger objets (prendre le plus d√©taill√©)
        objets = [r.get('objet', '') for r in results]
        consensus['objet'] = max(objets, key=len)
        
        # Merger TODOs (union)
        all_todos = []
        for r in results:
            all_todos.extend(r.get('todos', []))
        consensus['todos'] = all_todos[:5]  # Top 5
        
        return consensus
    
    async def _analyze_ollama(self, document: str) -> Dict:
        """Analyser avec Ollama local"""
        from src.services.fast_document_analyzer import fast_analyzer
        result = await fast_analyzer.analyze_quick(document)
        return result
    
    async def _analyze_gpt4(self, document: str) -> Dict:
        """Analyser avec GPT-4 (√† impl√©menter si API key disponible)"""
        # Placeholder - impl√©mentation r√©elle n√©cessite openai SDK
        import httpx
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY non configur√©")
        
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                'https://api.openai.com/v1/chat/completions',
                headers={'Authorization': f'Bearer {api_key}'},
                json={
                    'model': 'gpt-4o-mini',
                    'messages': [
                        {'role': 'system', 'content': 'Analyse ce document. Retourne JSON avec: urgence, delai_jours, type_document, objet.'},
                        {'role': 'user', 'content': document[:2000]}
                    ],
                    'temperature': 0.1,
                    'max_tokens': 500
                }
            )
            
            data = response.json()
            content = data['choices'][0]['message']['content']
            
            # Parser JSON
            import json
            return json.loads(content)
    
    async def _analyze_claude(self, document: str) -> Dict:
        """Analyser avec Claude (√† impl√©menter si API key disponible)"""
        # Placeholder similaire √† GPT-4
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY non configur√©")
        
        # Impl√©mentation Anthropic SDK
        raise NotImplementedError("Claude integration √† impl√©menter")
    
    def _calculate_cost(self, model: AIModel, text_length: int) -> float:
        """Calculer co√ªt approximatif"""
        # 1 token ‚âà 4 caract√®res
        tokens = text_length / 4
        cost_per_1k = self.costs[model]
        return (tokens / 1000) * cost_per_1k
    
    def _update_stats(self, model: AIModel, text_length: int):
        """Mettre √† jour statistiques usage"""
        tokens = text_length / 4
        cost = self._calculate_cost(model, text_length)
        
        self.usage_stats[model]['calls'] += 1
        self.usage_stats[model]['tokens'] += tokens
        self.usage_stats[model]['cost'] += cost
    
    def _get_routing_reason(self, document: str, context: Dict, model: AIModel) -> str:
        """Expliquer pourquoi ce mod√®le"""
        doc_length = len(document)
        
        if context.get('critical'):
            return "Document critique ‚Üí mod√®le haute qualit√©"
        elif context.get('priority') == 'urgent':
            return "Urgence ‚Üí mod√®le rapide"
        elif doc_length > 5000:
            return "Document long ‚Üí mod√®le meilleur context"
        elif model == AIModel.OLLAMA_LLAMA3:
            return "Document standard ‚Üí co√ªt optimis√© (local)"
        else:
            return "Routage par d√©faut"
    
    def get_usage_stats(self) -> Dict:
        """R√©cup√©rer statistiques usage"""
        return {
            'by_model': self.usage_stats,
            'total_cost': sum(s['cost'] for s in self.usage_stats.values()),
            'total_calls': sum(s['calls'] for s in self.usage_stats.values())
        }


# Instance globale
ai_router = IntelligentAIRouter()
