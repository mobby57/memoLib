{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac29426",
   "metadata": {},
   "source": [
    "# ğŸ“Š MemoLib Production Deployment Monitoring\n",
    "\n",
    "**Date**: 6 fÃ©vrier 2026  \n",
    "**Status**: ğŸš€ Deployment in Progress  \n",
    "**Objective**: Real-time monitoring of Phase 6 production deployment\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Setup Instructions\n",
    "\n",
    "1. Update `PRODUCTION_URL` below with your actual domain\n",
    "2. Run cells sequentially (top to bottom)\n",
    "3. Monitor metrics continuously\n",
    "4. Check success criteria at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# âš™ï¸ UPDATE THIS WITH YOUR PRODUCTION URL\n",
    "PRODUCTION_URL = \"https://your-production-domain.vercel.app\"  # Change this!\n",
    "LOCALHOST_URL = \"http://localhost:3000\"\n",
    "\n",
    "# Use localhost if production not available yet\n",
    "BASE_URL = PRODUCTION_URL if PRODUCTION_URL != \"https://your-production-domain.vercel.app\" else LOCALHOST_URL\n",
    "\n",
    "print(f\"âœ… Configured to monitor: {BASE_URL}\")\n",
    "print(f\"ğŸ“ Monitoring started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa8703",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Health Check - Is the API Responding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_health() -> Dict[str, Any]:\n",
    "    \"\"\"Check if API is responding\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/api/health\", timeout=10, verify=False)\n",
    "        status = \"âœ… HEALTHY\" if response.status_code == 200 else \"âŒ ERROR\"\n",
    "        \n",
    "        return {\n",
    "            \"status\": status,\n",
    "            \"http_code\": response.status_code,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"response_time_ms\": round(response.elapsed.total_seconds() * 1000)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"âŒ API NOT RESPONDING\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "# Run health check\n",
    "health = check_health()\n",
    "print(f\"Health Status: {health['status']}\")\n",
    "if 'http_code' in health:\n",
    "    print(f\"HTTP Code: {health['http_code']}\")\n",
    "    print(f\"Response Time: {health['response_time_ms']}ms\")\n",
    "else:\n",
    "    print(f\"Error: {health.get('error', 'Unknown')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a96cac",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Deployment Status - Is Production Ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deployment_status() -> Dict[str, Any]:\n",
    "    \"\"\"Check production deployment readiness\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/api/deployment/final-report\", timeout=10, verify=False)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return {\n",
    "                \"status\": data.get('status', 'Unknown'),\n",
    "                \"all_phases_complete\": data.get('allPhasesCompleted', False),\n",
    "                \"production_ready\": data.get('productionReady', False),\n",
    "                \"estimated_deploy_time\": data.get('estimatedProductionDeployment', 'Unknown'),\n",
    "                \"http_code\": response.status_code\n",
    "            }\n",
    "        else:\n",
    "            return {\"status\": \"Error\", \"http_code\": response.status_code}\n",
    "    except Exception as e:\n",
    "        return {\"status\": f\"Error: {str(e)}\"}\n",
    "\n",
    "# Run deployment status check\n",
    "deployment = check_deployment_status()\n",
    "print(f\"ğŸš€ Deployment Status: {deployment.get('status', 'Unknown')}\")\n",
    "print(f\"âœ… All Phases Complete: {deployment.get('all_phases_complete', False)}\")\n",
    "print(f\"âœ… Production Ready: {deployment.get('production_ready', False)}\")\n",
    "print(f\"â±ï¸  Estimated Deploy Time: {deployment.get('estimated_deploy_time', 'N/A')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb895ea1",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Real-Time Metrics - Monitor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics() -> Dict[str, Any]:\n",
    "    \"\"\"Get real-time metrics from dashboard\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/api/monitoring/metrics-dashboard\", timeout=10, verify=False)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return {\n",
    "                \"success_rate\": data.get('successRate', 0),\n",
    "                \"error_rate\": data.get('errorRate', 0),\n",
    "                \"p99_latency\": data.get('p99Latency', 0),\n",
    "                \"p95_latency\": data.get('p95Latency', 0),\n",
    "                \"cache_hit_rate\": data.get('cacheHitRate', 0),\n",
    "                \"total_events\": data.get('totalEvents', 0),\n",
    "                \"duplicate_rate\": data.get('duplicateRate', 0),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Get metrics\n",
    "metrics = get_metrics()\n",
    "\n",
    "if 'error' not in metrics:\n",
    "    print(\"ğŸ“Š REAL-TIME METRICS:\")\n",
    "    print(f\"âœ… Success Rate: {metrics['success_rate']:.2f}%\", end=\"\")\n",
    "    print(\" âœ…\" if metrics['success_rate'] > 95 else \" âš ï¸\" if metrics['success_rate'] > 90 else \" âŒ\")\n",
    "    \n",
    "    print(f\"âŒ Error Rate: {metrics['error_rate']:.2f}%\", end=\"\")\n",
    "    print(\" âœ…\" if metrics['error_rate'] < 5 else \" âš ï¸\" if metrics['error_rate'] < 10 else \" âŒ\")\n",
    "    \n",
    "    print(f\"â±ï¸  P99 Latency: {metrics['p99_latency']:.0f}ms\", end=\"\")\n",
    "    print(\" âœ…\" if metrics['p99_latency'] < 3000 else \" âš ï¸\" if metrics['p99_latency'] < 5000 else \" âŒ\")\n",
    "    \n",
    "    print(f\"â±ï¸  P95 Latency: {metrics['p95_latency']:.0f}ms\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ Cache Hit Rate: {metrics['cache_hit_rate']:.2f}%\", end=\"\")\n",
    "    print(\" âœ…\" if metrics['cache_hit_rate'] > 50 else \" âš ï¸\")\n",
    "    \n",
    "    print(f\"ğŸ“ˆ Total Events: {metrics['total_events']}\")\n",
    "    print(f\"ğŸ”„ Duplicate Rate: {metrics['duplicate_rate']:.2f}%\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Metrics not available yet: {metrics['error']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ed2ba",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Sentry Release Health - Error Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentry_health() -> Dict[str, Any]:\n",
    "    \"\"\"Check Sentry Release Health status\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/api/monitoring/release-health\", timeout=10, verify=False)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Check Sentry health\n",
    "sentry = check_sentry_health()\n",
    "\n",
    "print(\"ğŸ” SENTRY RELEASE HEALTH:\")\n",
    "if 'error' not in sentry:\n",
    "    print(f\"âœ… Status: {sentry.get('status', 'Unknown')}\")\n",
    "    print(f\"ğŸ“Š Session Count: {sentry.get('sessionCount', 0)}\")\n",
    "    print(f\"ğŸ’¥ Crash Rate: {sentry.get('crashRate', 0):.2f}%\", end=\"\")\n",
    "    print(\" âœ…\" if sentry.get('crashRate', 100) == 0 else \" âŒ\")\n",
    "    print(f\"ğŸš¨ Error Count: {sentry.get('errorCount', 0)}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Sentry health not available: {sentry['error']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821f1dc",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Smoke Tests - Validate Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ceb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_smoke_tests() -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Run smoke tests on critical endpoints\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Test 1: Health endpoint\n",
    "    try:\n",
    "        r = requests.get(f\"{BASE_URL}/api/health\", timeout=5, verify=False)\n",
    "        results['health'] = {\"pass\": r.status_code == 200, \"code\": r.status_code}\n",
    "    except:\n",
    "        results['health'] = {\"pass\": False, \"error\": \"timeout\"}\n",
    "    \n",
    "    # Test 2: Webhook validation\n",
    "    try:\n",
    "        payload = {\n",
    "            \"channel\": \"EMAIL\",\n",
    "            \"sender\": {\"email\": \"test@example.com\"},\n",
    "            \"body\": \"Test message\"\n",
    "        }\n",
    "        r = requests.post(\n",
    "            f\"{BASE_URL}/api/webhooks/test-multichannel/phase4\",\n",
    "            json=payload,\n",
    "            timeout=5,\n",
    "            verify=False\n",
    "        )\n",
    "        results['webhook'] = {\"pass\": r.status_code == 200, \"code\": r.status_code}\n",
    "    except:\n",
    "        results['webhook'] = {\"pass\": False, \"error\": \"timeout\"}\n",
    "    \n",
    "    # Test 3: Validation endpoint\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            f\"{BASE_URL}/api/test/webhook-validation\",\n",
    "            json={\"channel\": \"EMAIL\", \"sender\": {\"email\": \"test@example.com\"}, \"body\": \"test\"},\n",
    "            timeout=5,\n",
    "            verify=False\n",
    "        )\n",
    "        results['validation'] = {\"pass\": r.status_code in [200, 400], \"code\": r.status_code}\n",
    "    except:\n",
    "        results['validation'] = {\"pass\": False, \"error\": \"timeout\"}\n",
    "    \n",
    "    # Test 4: Metrics endpoint\n",
    "    try:\n",
    "        r = requests.get(f\"{BASE_URL}/api/monitoring/metrics-dashboard\", timeout=5, verify=False)\n",
    "        results['metrics'] = {\"pass\": r.status_code == 200, \"code\": r.status_code}\n",
    "    except:\n",
    "        results['metrics'] = {\"pass\": False, \"error\": \"timeout\"}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run smoke tests\n",
    "print(\"ğŸ§ª SMOKE TESTS:\")\n",
    "tests = run_smoke_tests()\n",
    "\n",
    "for test_name, result in tests.items():\n",
    "    status = \"âœ… PASS\" if result['pass'] else \"âŒ FAIL\"\n",
    "    print(f\"{status} - {test_name.upper()}\", end=\"\")\n",
    "    if 'code' in result:\n",
    "        print(f\" (HTTP {result['code']})\")\n",
    "    else:\n",
    "        print(f\" ({result.get('error', 'error')})\")\n",
    "\n",
    "passed = sum(1 for r in tests.values() if r.get('pass', False))\n",
    "total = len(tests)\n",
    "print(f\"\\nğŸ“Š Tests Passed: {passed}/{total}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b80a9",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Success Criteria Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9af904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_success_criteria() -> Dict[str, bool]:\n",
    "    \"\"\"Check if deployment meets success criteria\"\"\"\n",
    "    criteria = {}\n",
    "    \n",
    "    # Health check\n",
    "    health = check_health()\n",
    "    criteria['api_responding'] = health.get('status') == 'âœ… HEALTHY'\n",
    "    \n",
    "    # Deployment status\n",
    "    deployment = check_deployment_status()\n",
    "    criteria['production_ready'] = deployment.get('production_ready', False)\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = get_metrics()\n",
    "    criteria['success_rate_good'] = metrics.get('success_rate', 0) > 95\n",
    "    criteria['error_rate_low'] = metrics.get('error_rate', 100) < 10\n",
    "    criteria['latency_acceptable'] = metrics.get('p99_latency', 10000) < 5000\n",
    "    \n",
    "    # Sentry health  \n",
    "    sentry = check_sentry_health()\n",
    "    criteria['sentry_healthy'] = sentry.get('status') == 'Healthy' if 'status' in sentry else False\n",
    "    \n",
    "    # Smoke tests\n",
    "    tests = run_smoke_tests()\n",
    "    criteria['smoke_tests_pass'] = sum(1 for r in tests.values() if r.get('pass', False)) >= 3\n",
    "    \n",
    "    return criteria\n",
    "\n",
    "print(\"âœ… SUCCESS CRITERIA VALIDATION:\")\n",
    "criteria = validate_success_criteria()\n",
    "\n",
    "for criterion, passed in criteria.items():\n",
    "    status = \"âœ…\" if passed else \"âŒ\"\n",
    "    print(f\"{status} {criterion.replace('_', ' ').title()}\")\n",
    "\n",
    "total_passed = sum(1 for v in criteria.values() if v)\n",
    "total_criteria = len(criteria)\n",
    "\n",
    "print(f\"\\nğŸ“Š Criteria Met: {total_passed}/{total_criteria}\")\n",
    "\n",
    "if total_passed == total_criteria:\n",
    "    print(\"\\nğŸ‰ ALL SUCCESS CRITERIA MET - DEPLOYMENT SUCCESSFUL!\")\n",
    "elif total_passed >= total_criteria - 1:\n",
    "    print(f\"\\nâš ï¸  ALMOST THERE - {total_criteria - total_passed} criteria pending\")\n",
    "else:\n",
    "    print(f\"\\nâŒ {total_criteria - total_passed} criteria not met yet - monitoring...\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75901946",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Continuous Monitoring Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitoring_loop(iterations: int = 12, interval: int = 30):\n",
    "        \"\"\"Run continuous monitoring loop\n",
    "        \n",
    "        Args:\n",
    "            iterations: How many times to check (default 12 = 6 minutes at 30sec intervals)\n",
    "            interval: Seconds between checks (default 30)\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ”„ Starting monitoring loop - {iterations} iterations every {interval}s ({iterations * interval / 60:.1f} min total)\")\n",
    "        print(\"Press Ctrl+C to stop\\n\")\n",
    "        \n",
    "        try:\n",
    "            for i in range(iterations):\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"Check #{i+1}/{iterations} - {datetime.now().strftime('%H:%M:%S')}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                metrics = get_metrics()\n",
    "                if 'error' not in metrics:\n",
    "                    print(f\"âœ… Success Rate: {metrics['success_rate']:.2f}%\")\n",
    "                    print(f\"âŒ Error Rate: {metrics['error_rate']:.2f}%\")\n",
    "                    print(f\"â±ï¸  P99 Latency: {metrics['p99_latency']:.0f}ms\")\n",
    "                    print(f\"ğŸ’¾ Cache Hit: {metrics['cache_hit_rate']:.2f}%\")\n",
    "                    print(f\"ğŸ“ˆ Events: {metrics['total_events']}\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸  Metrics unavailable: {metrics['error']}\")\n",
    "                \n",
    "                if i < iterations - 1:\n",
    "                    print(f\"â³ Next check in {interval}s...\", end=\"\")\n",
    "                    time.sleep(interval)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nâ¹ï¸  Monitoring stopped by user\")\n",
    "\n",
    "# Ready to run - uncomment to execute continuous monitoring\n",
    "print(\"ğŸ“Œ To run continuous monitoring, uncomment and run:\")\n",
    "print(\"# monitoring_loop(iterations=12, interval=30)\")\n",
    "print(\"\\nOr modify parameters:\")\n",
    "print(\"# monitoring_loop(iterations=60, interval=10) # 10 minutes at 10-second intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48b57f",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Final Deployment Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc115590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\nğŸ¯ DEPLOYMENT CHECKLIST:\n",
    "\n",
    "BEFORE PRODUCTION:\n",
    "â˜ Update PRODUCTION_URL variable at top of notebook\n",
    "â˜ Verify environment variables configured on platform\n",
    "â˜ Confirm database migrations applied\n",
    "â˜ Enable Sentry Release Health\n",
    "\n",
    "AFTER MERGE TO MAIN:\n",
    "â˜ Monitor auto-deploy on Vercel/Render dashboard\n",
    "â˜ Wait for 'Building...' â†’ 'Ready' status (5-10 min)\n",
    "â˜ Run Health Check cell above\n",
    "â˜ Run Smoke Tests cell\n",
    "â˜ Monitor metrics for 5-10 minutes\n",
    "â˜ Check success criteria\n",
    "\n",
    "SUCCESS TARGETS:\n",
    "âœ… Success Rate: > 98% (accept > 95% first 30 min)\n",
    "âœ… Error Rate: < 2% (accept < 5% first 30 min)\n",
    "âœ… P99 Latency: < 3000ms\n",
    "âœ… All Smoke Tests: Pass\n",
    "âœ… Sentry Health: Healthy\n",
    "âœ… No Critical Errors: 0\n",
    "\n",
    "ROLLBACK TRIGGERS (AUTOMATIC):\n",
    "âŒ Error rate > 5% for 5+ minutes\n",
    "âŒ P99 latency > 5000ms for 5+ minutes\n",
    "âŒ Database connection failures > 20%\n",
    "\n",
    "RESOURCES:\n",
    "ğŸ“Š Sentry: https://sentry.io/organizations/memolib/releases/\n",
    "ğŸ”— Vercel: https://vercel.com/dashboard\n",
    "ğŸ”— Render: https://dashboard.render.com\n",
    "ğŸ“– Deployment Guide: DEPLOYMENT_EXECUTION_CHECKLIST.md\n",
    "ğŸ“– Monitoring Guide: PRODUCTION_MONITORING_GUIDE.md\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9f828",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Notebook Version**: 1.0  \n",
    "**Created**: 2026-02-06  \n",
    "**Status**: âœ… Production Ready  \n",
    "**Next Steps**: Update PRODUCTION_URL â†’ Run all cells â†’ Monitor continuously"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
