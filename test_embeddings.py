"""
Test du service Embeddings OpenAI
"""
import os
import sys
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Ajouter le r√©pertoire src au path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from backend.app import UnifiedAIService

def test_embeddings():
    print("=" * 60)
    print("TEST OPENAI EMBEDDINGS API")
    print("=" * 60)
    
    # R√©cup√©rer la cl√© API
    api_key = os.environ.get('OPENAI_API_KEY')
    
    if not api_key:
        print("‚ùå ERREUR: OPENAI_API_KEY non trouv√©e dans .env")
        return False
    
    print(f"‚úì Cl√© API trouv√©e: {api_key[:10]}...")
    
    # Initialiser le service AI avec la cl√©
    ai_service = UnifiedAIService(api_key=api_key)
    
    # Test 1: Embedding simple
    print("\nüìù Test 1: Cr√©ation d'un embedding simple")
    print("-" * 60)
    
    test_text = "Bonjour, je souhaite obtenir des informations sur mon colis."
    result = ai_service.create_embedding(test_text)
    
    if result['success']:
        print(f"‚úÖ SUCC√àS")
        print(f"   Mod√®le: {result['model']}")
        print(f"   Dimensions: {result['dimensions']}")
        print(f"   Tokens utilis√©s: {result['tokens_used']}")
        print(f"   Embedding (5 premi√®res valeurs): {result['embedding'][:5]}")
        print(f"   Request ID: {result['request_id']}")
    else:
        print(f"‚ùå √âCHEC: {result.get('error')}")
        return False
    
    # Test 2: Batch embeddings
    print("\nüìù Test 2: Cr√©ation de plusieurs embeddings en batch")
    print("-" * 60)
    
    test_texts = [
        "Suivi de colis num√©ro 123456789",
        "Demande de remboursement suite √† un colis endommag√©",
        "Modification d'adresse de livraison",
        "Question sur les d√©lais de livraison"
    ]
    
    batch_result = ai_service.batch_create_embeddings(test_texts)
    
    if batch_result['success']:
        print(f"‚úÖ SUCC√àS")
        print(f"   Nombre d'embeddings: {batch_result['count']}")
        print(f"   Tokens utilis√©s: {batch_result['tokens_used']}")
        print(f"   Mod√®le: {batch_result['model']}")
        
        for idx, emb in enumerate(batch_result['embeddings']):
            print(f"   - Texte {emb['index']}: {len(emb['embedding'])} dimensions")
    else:
        print(f"‚ùå √âCHEC: {batch_result.get('error')}")
        return False
    
    # Test 3: Calcul de similarit√©
    print("\nüìù Test 3: Calcul de similarit√© entre textes")
    print("-" * 60)
    
    # Cr√©er embeddings pour deux textes similaires
    text1 = "O√π est mon colis ?"
    text2 = "Je veux suivre mon colis"
    text3 = "Comment changer mon mot de passe ?"
    
    emb1 = ai_service.create_embedding(text1)
    emb2 = ai_service.create_embedding(text2)
    emb3 = ai_service.create_embedding(text3)
    
    if emb1['success'] and emb2['success'] and emb3['success']:
        # Similarit√© entre textes similaires (suivi de colis)
        similarity_similar = ai_service.calculate_similarity(
            emb1['embedding'], 
            emb2['embedding']
        )
        
        # Similarit√© entre textes diff√©rents
        similarity_different = ai_service.calculate_similarity(
            emb1['embedding'], 
            emb3['embedding']
        )
        
        print(f"‚úÖ SUCC√àS")
        print(f"   Texte 1: '{text1}'")
        print(f"   Texte 2: '{text2}'")
        print(f"   Similarit√© (similaires): {similarity_similar:.4f}")
        print()
        print(f"   Texte 1: '{text1}'")
        print(f"   Texte 3: '{text3}'")
        print(f"   Similarit√© (diff√©rents): {similarity_different:.4f}")
        
        # V√©rifier que les textes similaires ont un score plus √©lev√©
        if similarity_similar > similarity_different:
            print(f"\n   ‚úì Les textes similaires ont bien un score plus √©lev√©!")
        else:
            print(f"\n   ‚ö† Attention: scores inattendus")
    else:
        print(f"‚ùå √âCHEC lors de la cr√©ation des embeddings")
        return False
    
    # Test 4: Test avec le mod√®le text-embedding-3-small (plus r√©cent)
    print("\nüìù Test 4: Test avec text-embedding-3-small")
    print("-" * 60)
    
    result_v3 = ai_service.create_embedding(
        test_text, 
        model="text-embedding-3-small",
        dimensions=512  # Version r√©duite pour √©conomiser
    )
    
    if result_v3['success']:
        print(f"‚úÖ SUCC√àS")
        print(f"   Mod√®le: {result_v3['model']}")
        print(f"   Dimensions: {result_v3['dimensions']}")
        print(f"   Tokens utilis√©s: {result_v3['tokens_used']}")
    else:
        # Le mod√®le v3 pourrait ne pas √™tre disponible selon le compte
        print(f"‚ö† Mod√®le v3 non disponible (normal): {result_v3.get('error')}")
    
    # R√©sum√© final
    print("\n" + "=" * 60)
    print("üéâ TOUS LES TESTS R√âUSSIS!")
    print("=" * 60)
    print("\nCas d'usage possibles:")
    print("  ‚Ä¢ Recherche s√©mantique d'emails")
    print("  ‚Ä¢ Classification automatique de messages")
    print("  ‚Ä¢ D√©tection de doublons/messages similaires")
    print("  ‚Ä¢ Suggestions de r√©ponses bas√©es sur la similarit√©")
    print("  ‚Ä¢ Clustering de conversations par th√®me")
    
    return True

if __name__ == "__main__":
    try:
        success = test_embeddings()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
