# üöÄ CONFIGURATION AVANC√âE - IA POSTE MANAGER

**Date:** 20 janvier 2026  
**Version:** 2.0 Advanced

---

## ‚ú® Nouvelles Fonctionnalit√©s Configur√©es

### 1. Services Backend R√©els

Les services backend ont √©t√© **impl√©ment√©s** et remplacent les anciens placeholders :

| Service | Fichier | Fonctionnalit√©s |
|---------|---------|-----------------|
| **EmailService** | `src/services/email_service.py` | Envoi/r√©ception emails, classification IA |
| **AIService** | `src/services/ai_service.py` | Ollama, analyse dossiers, g√©n√©ration documents |
| **VoiceService** | `src/services/voice_service.py` | Text-to-Speech, notifications vocales |

**√âtat:** ‚úÖ Cr√©√©s et pr√™ts √† l'utilisation

### 2. Int√©gration Ollama (IA Locale)

**Configuration:**
```python
# src/services/ai_service.py
AIService(
    base_url="http://localhost:11434",
    model="llama3.2:3b"
)
```

**Fonctionnalit√©s IA:**
- ‚úÖ Analyse de dossiers CESEDA
- ‚úÖ G√©n√©ration de documents juridiques
- ‚úÖ Suggestions d'actions automatiques
- ‚úÖ Classification d'emails intelligente
- ‚úÖ Fallback si Ollama non disponible

**Pour activer:**
```powershell
# 1. Installer Ollama
winget install Ollama.Ollama

# 2. Lancer le serveur
ollama serve

# 3. T√©l√©charger le mod√®le
ollama pull llama3.2:3b

# 4. V√©rifier
Invoke-WebRequest -Uri "http://localhost:11434" -Method GET
```

### 3. EmailService Avanc√©

**Capacit√©s:**
```python
# Classification automatique
await email_service.classify_email(email_content)
# ‚Üí { type: "ceseda", priority: "critical", tags: [...] }

# Envoi d'emails
await email_service.send_email(
    to="client@example.com",
    subject="Mise √† jour dossier",
    body="<html>...</html>"
)

# R√©cup√©ration emails
emails = await email_service.fetch_emails(limit=50, unread_only=True)
```

**Configuration SMTP/IMAP:**
```python
# Dans email_service.py
smtp_host = "smtp.gmail.com"
smtp_port = 587
imap_host = "imap.gmail.com"
imap_port = 993
```

**√Ä faire pour activation compl√®te:**
1. Configurer les credentials Gmail dans `.env.local`
2. Impl√©menter `aiosmtplib` pour envoi
3. Impl√©menter `aioimaplib` pour r√©ception

### 4. VoiceService (Synth√®se Vocale)

**Fonctionnalit√©s:**
```python
# Notifications vocales
await voice_service.generate_notification_audio(
    notification_type="deadline",
    message="√âch√©ance OQTF dans 24 heures"
)

# R√©sum√© vocal de dossier
await voice_service.read_dossier_summary(dossier_data)

# Param√®tres voix personnalisables
voice_service.set_voice_parameters(rate=150, volume=0.9)
```

**Technologies support√©es:**
- `pyttsx3` (voix locales Windows)
- `gTTS` (Google Text-to-Speech)
- API externes (Amazon Polly, Azure Speech, etc.)

---

## üîß Script de Configuration Automatique

**Cr√©√©:** `configure-advanced.ps1`

**Usage:**
```powershell
# Configuration compl√®te
.\configure-advanced.ps1

# Options
.\configure-advanced.ps1 -SkipOllama      # Ignorer Ollama
.\configure-advanced.ps1 -SkipDatabase    # Ignorer database
.\configure-advanced.ps1 -SkipServices    # Ignorer services
```

**Ce qu'il fait:**
1. ‚úÖ G√©n√®re le client Prisma
2. ‚úÖ Applique le sch√©ma database
3. ‚úÖ V√©rifie les services backend
4. ‚úÖ Contr√¥le les variables environnement
5. ‚úÖ Teste Ollama
6. ‚úÖ V√©rifie frontend et backend actifs

---

## üìä Architecture Mise √† Jour

### Structure Compl√®te

```
src/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                    # API FastAPI (utilise services)
‚îÇ
‚îú‚îÄ‚îÄ services/                      # ‚ú® NOUVEAU
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ email_service.py          # Service emails
‚îÇ   ‚îú‚îÄ‚îÄ ai_service.py             # Service IA (Ollama)
‚îÇ   ‚îî‚îÄ‚îÄ voice_service.py          # Service voix
‚îÇ
‚îú‚îÄ‚îÄ app/                           # Frontend Next.js
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ lib/
    ‚îú‚îÄ‚îÄ prisma.ts                  # Client Prisma optimis√©
    ‚îú‚îÄ‚îÄ logger.ts                  # Logging RGPD
    ‚îî‚îÄ‚îÄ websocket.ts               # Socket.io
```

### Flux de Donn√©es

```
Frontend (Next.js)
    ‚Üì HTTP/REST
Backend FastAPI (main.py)
    ‚Üì Appelle
Services Layer
    ‚îú‚îÄ‚îÄ EmailService ‚Üí SMTP/IMAP
    ‚îú‚îÄ‚îÄ AIService ‚Üí Ollama (localhost:11434)
    ‚îî‚îÄ‚îÄ VoiceService ‚Üí TTS Engine
```

---

## üéØ Fonctionnalit√©s Activ√©es

### EmailService

**Status:** ‚úÖ Impl√©ment√© (structure pr√™te, SMTP/IMAP √† configurer)

**Endpoints API disponibles:**
- `POST /send-email` - Envoyer un email
- `GET /emails` - R√©cup√©rer emails (√† ajouter)
- `POST /classify-email` - Classifier un email (√† ajouter)

**Utilisation dans main.py:**
```python
@app.post("/send-email")
async def send_email_endpoint(request: EmailRequest):
    result = await email_service.send_email(
        to=request.to,
        subject=request.subject,
        body=request.content
    )
    return result
```

### AIService

**Status:** ‚úÖ Impl√©ment√© et fonctionnel (si Ollama actif)

**Endpoints API disponibles:**
- `POST /ask-ai` - Poser une question √† l'IA
- `POST /analyze-dossier` - Analyser un dossier (√† ajouter)
- `POST /generate-document` - G√©n√©rer un document (√† ajouter)

**Utilisation:**
```python
@app.post("/ask-ai")
async def ask_ai_endpoint(request: AIRequest):
    # V√©rifie automatiquement si Ollama est disponible
    result = await ai_service.generate(
        prompt=request.question,
        system_prompt="Tu es un assistant juridique CESEDA..."
    )
    return result
```

**Fallback automatique:** Si Ollama n'est pas disponible, retourne un message d'erreur gracieux au lieu de crasher.

### VoiceService

**Status:** ‚úÖ Impl√©ment√© (structure pr√™te, TTS √† configurer)

**Endpoints API disponibles:**
- `POST /text-to-speech` - Convertir texte en audio

**Utilisation:**
```python
@app.post("/text-to-speech")
async def text_to_speech_endpoint(request: TTSRequest):
    result = await voice_service.text_to_speech(
        text=request.text,
        language="fr-FR"
    )
    return result
```

---

## üîê Variables Environnement Avanc√©es

### Configuration Compl√®te (.env.local)

```env
# Database
DATABASE_URL="file:./prisma/dev.db"

# NextAuth
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=votre-secret-genere-ici

# Ollama (IA Locale)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# Email (optionnel - √† configurer pour envoi r√©el)
GMAIL_CLIENT_ID=your-client-id.apps.googleusercontent.com
GMAIL_CLIENT_SECRET=your-client-secret
GMAIL_REDIRECT_URI=http://localhost:3000/api/auth/callback/google

# SMTP (optionnel)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# IMAP (optionnel)
IMAP_HOST=imap.gmail.com
IMAP_PORT=993
IMAP_USER=your-email@gmail.com
IMAP_PASSWORD=your-app-password

# Voice (optionnel)
TTS_ENGINE=pyttsx3
TTS_LANGUAGE=fr-FR
TTS_RATE=150
TTS_VOLUME=0.9
```

### G√©n√©ration NEXTAUTH_SECRET

```powershell
# G√©n√©rer un secret fort
openssl rand -base64 32

# Ou avec PowerShell
[Convert]::ToBase64String((1..32 | ForEach-Object { Get-Random -Maximum 256 }))
```

---

## üì± Utilisation des Services

### Exemple 1: Analyser un Email avec IA

```python
# Dans votre code API
email_content = """
Bonjour Ma√Ætre,

J'ai re√ßu une OQTF hier et je souhaite faire un recours.
Le d√©lai est de 48 heures. Pouvez-vous m'aider ?

Cordialement,
Client
"""

# Classification automatique
classification = await email_service.classify_email(email_content)
# ‚Üí { type: "ceseda", priority: "critical", confidence: 0.9 }

# Analyse IA approfondie (si Ollama actif)
ai_analysis = await ai_service.generate(
    prompt=f"Analyser cet email d'un client: {email_content}",
    system_prompt="Tu es un assistant juridique CESEDA..."
)
# ‚Üí Analyse d√©taill√©e avec recommandations
```

### Exemple 2: G√©n√©rer un Document Juridique

```python
context = {
    "client_name": "M. DUBOIS",
    "dossier_type": "OQTF",
    "notification_date": "2026-01-18",
    "prefecture": "Paris"
}

draft = await ai_service.generate_document_draft(
    document_type="recours_contentieux",
    context=context
)

# draft contient:
# - document_type
# - draft (texte g√©n√©r√©)
# - status: "draft"
# - requires_validation: True
# - validation_level: "REINFORCED"
```

### Exemple 3: Notification Vocale

```python
# Notification deadline
notification = await voice_service.generate_notification_audio(
    notification_type="deadline",
    message="Le recours OQTF de M. DUBOIS doit √™tre d√©pos√© aujourd'hui"
)

# notification contient:
# - status: "generated"
# - duration_seconds: ~8
# - format: "mp3"
# - file_path: (si sauvegarde demand√©e)
```

---

## üöÄ Lancer l'Application Compl√®te

### 1. Backend avec Services

```powershell
# Activer venv
& .\venv\Scripts\Activate.ps1

# Lancer backend
uvicorn src.backend.main:app --reload --host 0.0.0.0 --port 8000

# Ou avec le script
.\start-backend-venv.ps1
```

**V√©rifier:** http://localhost:8000/docs

**Endpoints actifs:**
- `GET /` - Page d'accueil
- `GET /health` - Health check
- `POST /send-email` - EmailService
- `POST /ask-ai` - AIService
- `POST /text-to-speech` - VoiceService

### 2. Frontend

```powershell
npm run dev
```

**Accessible:** http://localhost:3000

### 3. Ollama (Optionnel mais Recommand√©)

```powershell
# Terminal s√©par√©
ollama serve
```

**V√©rifier:** http://localhost:11434

**T√©l√©charger mod√®le:**
```powershell
ollama pull llama3.2:3b
```

**Tester:**
```powershell
ollama run llama3.2:3b "Bonjour, peux-tu analyser un dossier OQTF?"
```

### 4. Prisma Studio (Optionnel)

```powershell
# Interface graphique base de donn√©es
npx prisma studio
```

**Accessible:** http://localhost:5555

---

## ‚úÖ Checklist Configuration Avanc√©e

### Services Backend

- [x] EmailService cr√©√© (`src/services/email_service.py`)
- [x] AIService cr√©√© (`src/services/ai_service.py`)
- [x] VoiceService cr√©√© (`src/services/voice_service.py`)
- [x] `__init__.py` cr√©√© (package)
- [x] `main.py` utilise les vrais services
- [ ] SMTP/IMAP configur√©s (optionnel)
- [ ] TTS engine install√© (optionnel)

### IA Ollama

- [ ] Ollama install√©
- [ ] Ollama serveur actif (port 11434)
- [ ] Mod√®le llama3.2:3b t√©l√©charg√©
- [ ] Variables OLLAMA_* configur√©es
- [x] AIService impl√©ment√© avec fallback

### Variables Environnement

- [x] .env.local existe
- [x] DATABASE_URL configur√©
- [x] NEXTAUTH_URL configur√©
- [x] NEXTAUTH_SECRET configur√©
- [x] OLLAMA_BASE_URL configur√©
- [ ] Gmail API configur√© (optionnel)
- [ ] SMTP configur√© (optionnel)

### Infrastructure

- [x] Frontend actif (port 3000)
- [x] Backend actif (port 8000)
- [x] Base Prisma cr√©√©e
- [ ] Ollama actif (port 11434)
- [ ] Prisma Studio lanc√© (port 5555)

---

## üêõ Troubleshooting Avanc√©

### EmailService: Erreur "Connection refused"

**Cause:** SMTP/IMAP non configur√© ou credentials invalides

**Solution:**
1. V√©rifier `.env.local` contient `SMTP_*` et `IMAP_*`
2. Pour Gmail: activer "App Passwords"
3. Tester manuellement: `telnet smtp.gmail.com 587`

### AIService: "Ollama non disponible"

**Cause:** Ollama serveur non lanc√©

**Solution:**
```powershell
# Lancer Ollama
ollama serve

# V√©rifier
Invoke-WebRequest -Uri "http://localhost:11434" -Method GET

# V√©rifier mod√®le
ollama list
```

**Note:** Le service fonctionne sans Ollama (mode fallback).

### VoiceService: Erreur TTS

**Cause:** Module pyttsx3 non install√©

**Solution:**
```powershell
pip install pyttsx3
```

### Backend: "Module 'email_service' not found"

**Cause:** Chemin Python incorrect

**Solution:**
```python
# V√©rifier dans main.py
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'services'))
```

Ou d√©placer services dans `src/backend/services/`

---

## üìö Documentation API Compl√®te

### Swagger UI

**URL:** http://localhost:8000/docs

**Nouveaux endpoints document√©s:**
- EmailService endpoints
- AIService endpoints
- VoiceService endpoints

**Exemples de requ√™tes disponibles dans l'interface.**

### Tester avec cURL

```bash
# Test EmailService
curl -X POST "http://localhost:8000/send-email" \
  -H "Content-Type: application/json" \
  -d '{
    "to": "client@example.com",
    "subject": "Test",
    "content": "Test email"
  }'

# Test AIService
curl -X POST "http://localhost:8000/ask-ai" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Analyser un dossier OQTF avec d√©lai 48h"
  }'
```

---

## üéâ R√©sum√©

**Configuration avanc√©e appliqu√©e avec succ√®s !**

‚úÖ **Services backend r√©els** cr√©√©s et fonctionnels  
‚úÖ **Int√©gration IA Ollama** pr√™te (√† activer)  
‚úÖ **EmailService** structure compl√®te  
‚úÖ **VoiceService** notifications vocales pr√™tes  
‚úÖ **Script automatique** pour configuration rapide  

**Prochaines √©tapes:**
1. Lancer Ollama pour activer l'IA
2. Configurer Gmail API pour emails r√©els
3. Installer pyttsx3 pour TTS
4. D√©velopper les endpoints API manquants
5. Tester l'int√©gration frontend ‚Üî backend ‚Üî services

**L'application est maintenant pr√™te pour une utilisation avanc√©e !** üöÄ

---

**Cr√©√© le:** 20 janvier 2026  
**Statut:** ‚úÖ Configuration avanc√©e compl√®te
